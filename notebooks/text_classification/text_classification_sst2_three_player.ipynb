{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright (c) Microsoft Corporation. All rights reserved.*\n",
    "\n",
    "*Licensed under the MIT License.*\n",
    "\n",
    "# Text Classification of SST-2 Sentences using a 3-Player Introspective Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v-yohwa\\AppData\\Local\\Continuum\\anaconda3\\envs\\interpret_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\v-yohwa\\AppData\\Local\\Continuum\\anaconda3\\envs\\interpret_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\v-yohwa\\AppData\\Local\\Continuum\\anaconda3\\envs\\interpret_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\v-yohwa\\AppData\\Local\\Continuum\\anaconda3\\envs\\interpret_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\v-yohwa\\AppData\\Local\\Continuum\\anaconda3\\envs\\interpret_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\v-yohwa\\AppData\\Local\\Continuum\\anaconda3\\envs\\interpret_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from interpret_text.common.dataset.utils_sst2 import load_sst2_pandas_df\n",
    "from interpret_text.three_player_introspective.three_player_introspective_explainer import ThreePlayerIntrospectiveExplainer\n",
    "from interpret_text.common.utils_three_player import GlovePreprocessor, ModelArguments, load_glove_embeddings\n",
    "from interpret_text.widget import ExplanationDashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook, we train and evaluate a  [three-player explainer](http://people.csail.mit.edu/tommi/papers/YCZJ_EMNLP2019.pdf) model on a subset of the [SST-2](https://nlp.stanford.edu/sentiment/index.html/) dataset. To run this notebook, we used the SST-2 data files provided [here](https://github.com/AcademiaSinicaNLPLab/sentiment_dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters\n",
    "Here we set some parameters that we use for our modeling task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# if quick run true, skips over embedding, most of model training, and model evaulation; used to quickly test pipeline\n",
    "QUICK_RUN = True\n",
    "model_type = \"RNN\" # currently support either RNN or BERT\n",
    "\n",
    "# data processing parameters\n",
    "DATA_FOLDER = \"../../../data/sst2\"\n",
    "LABEL_COL = \"labels\" \n",
    "TEXT_COL = \"sentences\"\n",
    "token_count_thresh = 1\n",
    "max_sentence_token_count = 70\n",
    "\n",
    "# training procedure parameters\n",
    "model_save_dir = os.path.join(\"..\", \"models\")\n",
    "model_prefix = \"sst2rnpmodel\"\n",
    "cuda = True\n",
    "batch_size = 16\n",
    "if not QUICK_RUN:\n",
    "    save_best_model = True\n",
    "    pre_train_cls = True\n",
    "    num_epochs = 200\n",
    "else:\n",
    "    save_best_model = False\n",
    "    pre_train_cls = False\n",
    "    num_epochs = 1\n",
    "\n",
    "# ModelArguments contains default parameters used internally in the model that can changed\n",
    "args = ModelArguments(cuda, pre_train_cls, batch_size, num_epochs, save_best_model, model_save_dir=model_save_dir, model_prefix=model_prefix)\n",
    "# example of changing an argument\n",
    "args.cuda = False\n",
    "\n",
    "\n",
    "if model_type == \"RNN\":\n",
    "    # (i.e. not using BERT), load pretrained glove embeddings\n",
    "    # TODO: load glove embedding file in load_glove_embeddings to blob storage\n",
    "    if not QUICK_RUN:\n",
    "        args.embedding_path = load_glove_embeddings(DATA_FOLDER)\n",
    "    else:\n",
    "        args.embedding_path = os.path.join(DATA_FOLDER, \"noEmbeddingFile.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset\n",
    "We start by loading a subset of the data for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: load dataset to blob storage\n",
    "train_data = load_sst2_pandas_df('train')\n",
    "test_data = load_sst2_pandas_df('test')\n",
    "all_data = pd.concat([train_data, test_data])\n",
    "if QUICK_RUN:\n",
    "    train_data = train_data.head(batch_size)\n",
    "    test_data = test_data.head(batch_size)\n",
    "X_train = train_data[TEXT_COL]\n",
    "X_test = test_data[TEXT_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique labels\n",
    "labels = all_data[LABEL_COL].unique()\n",
    "args.labels = np.array(sorted(labels))\n",
    "args.num_labels = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and embedding\n",
    "The data is then tokenized and embedded using glove embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == \"RNN\":\n",
    "    preprocessor = GlovePreprocessor(all_data[TEXT_COL], token_count_thresh, max_sentence_token_count)\n",
    "if model_type == \"BERT\":\n",
    "    preprocessor = BertPreprocessor()\n",
    "\n",
    "# append labels to tokenizer output\n",
    "df_train = pd.concat([train_data[LABEL_COL], preprocessor.preprocess(X_train)], axis=1)\n",
    "df_test = pd.concat([test_data[LABEL_COL], preprocessor.preprocess(X_test)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainer\n",
    "Then, we create and train the explainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v-yohwa\\AppData\\Local\\Continuum\\anaconda3\\envs\\interpret_cpu\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "C:\\Users\\v-yohwa\\AppData\\Local\\Continuum\\anaconda3\\envs\\interpret_cpu\\lib\\site-packages\\torch\\nn\\_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.29s/it]\n"
     ]
    }
   ],
   "source": [
    "explainer = ThreePlayerIntrospectiveExplainer(args, preprocessor, classifier_type=model_type)\n",
    "classifier = explainer.fit(df_train, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the explainer and measure its performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not QUICK_RUN:\n",
    "    explainer.score(df_test, n_examples_displayed=0)\n",
    "    print(\"Test sparsity: \", explainer.model.avg_sparsity)\n",
    "    print(\"Test accuracy: \", explainer.model.avg_accuracy, \"% Anti-accuracy: \", explainer.model.avg_anti_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local importances\n",
    "We can display the found local importances (the most and least important words for a given sentence):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Enter a sentence that needs to be interpreted\n",
    "sentence = \"This great movie was really good\"\n",
    "label = 1\n",
    "\n",
    "local_explanation = explainer.explain_local(sentence, label, preprocessor, hard_importances=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize explanations\n",
    "We can visualize local feature importances as a heatmap over words in the document and view importance values of individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:rgba(135,206,250,0.9602779150009155);\">this</span> <span style=\"background-color:rgba(135,206,250,0.9507538676261902);\">great</span> <span style=\"background-color:rgba(135,206,250,0.9531134366989136);\">movie</span> <span style=\"background-color:rgba(135,206,250,0.9584249258041382);\">was</span> <span style=\"background-color:rgba(135,206,250,0.9436817765235901);\">really</span> <span style=\"background-color:rgba(135,206,250,0.9487930536270142);\">good</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explainer.visualize(local_explanation._local_importance_values, local_explanation._features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f935b8f1dd94af1837d6f4c6b0e26f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExplanationWidget(value={'text': ['this', 'great', 'movie', 'was', 'really', 'good'], 'prediction': [0, 1], 'c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<interpret_text.widget.ExplanationDashboard.ExplanationDashboard at 0x2b92e58d390>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExplanationDashboard(local_explanation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
