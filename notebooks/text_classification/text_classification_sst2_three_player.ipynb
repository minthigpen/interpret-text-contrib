{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright (c) Microsoft Corporation. All rights reserved.*\n",
    "\n",
    "*Licensed under the MIT License.*\n",
    "\n",
    "# Text Classification of SST-2 Sentences using a 3-Player Introspective Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v-yohwa\\AppData\\Local\\Continuum\\anaconda3\\envs\\interpret_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\v-yohwa\\AppData\\Local\\Continuum\\anaconda3\\envs\\interpret_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\v-yohwa\\AppData\\Local\\Continuum\\anaconda3\\envs\\interpret_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\v-yohwa\\AppData\\Local\\Continuum\\anaconda3\\envs\\interpret_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\v-yohwa\\AppData\\Local\\Continuum\\anaconda3\\envs\\interpret_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\v-yohwa\\AppData\\Local\\Continuum\\anaconda3\\envs\\interpret_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from interpret_text.common.dataset.utils_sst2 import load_sst2_pandas_df\n",
    "from interpret_text.three_player_introspective.three_player_introspective_explainer import ThreePlayerIntrospectiveExplainer\n",
    "from interpret_text.common.utils_three_player import GlovePreprocessor, ModelArguments, load_glove_embeddings\n",
    "from interpret_text.widget import ExplanationDashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook, we train and evaluate a  [three-player explainer](http://people.csail.mit.edu/tommi/papers/YCZJ_EMNLP2019.pdf) model on a subset of the [SST-2](https://nlp.stanford.edu/sentiment/index.html/) dataset. To run this notebook, we used the SST-2 data files provided [here](https://github.com/AcademiaSinicaNLPLab/sentiment_dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters\n",
    "Here we set some parameters that we use for our modeling task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# if true, skips over embedding, most of model training, and model evaulation; used to test notebook flow\n",
    "QUICK_RUN = True\n",
    "\n",
    "# data processing parameters\n",
    "DATA_FOLDER = \"../../../data/sst2\"\n",
    "LABEL_COL = \"labels\" \n",
    "TEXT_COL = \"sentences\"\n",
    "token_count_thresh = 1\n",
    "max_sentence_token_count = 70\n",
    "\n",
    "# training procedure parameters\n",
    "model_save_dir = os.path.join(\"..\", \"models\")\n",
    "model_prefix = \"sst2rnpmodel\"\n",
    "cuda = True\n",
    "batch_size = 200\n",
    "if not QUICK_RUN:\n",
    "    save_best_model = True\n",
    "    pre_train_cls = True\n",
    "    num_epochs = 200\n",
    "else:\n",
    "    save_best_model = True\n",
    "    pre_train_cls = False\n",
    "    num_epochs = 1\n",
    "\n",
    "# ModelArguments contains default parameters used internally in the model that can changed\n",
    "args = ModelArguments(cuda, pre_train_cls, batch_size, num_epochs, save_best_model, model_save_dir=model_save_dir, model_prefix=model_prefix)\n",
    "# example of changing an argument\n",
    "args.cuda = False\n",
    "\n",
    "# If using glove embeddings (i.e. not using BERT), load pretrained embeddings\n",
    "# TODO: load glove embedding file in load_glove_embeddings to blob storage\n",
    "if not QUICK_RUN:\n",
    "    args.embedding_path = load_glove_embeddings(DATA_FOLDER)\n",
    "else:\n",
    "    args.embedding_path = os.path.join(DATA_FOLDER, \"noEmbeddingFile.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset\n",
    "We start by loading a subset of the data for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: load dataset to blob storage\n",
    "train_data = load_sst2_pandas_df('train')\n",
    "test_data = load_sst2_pandas_df('test')\n",
    "if QUICK_RUN:\n",
    "    train_data = train_data.head(batch_size)\n",
    "    test_data = test_data.head(batch_size)\n",
    "all_data = pd.concat([train_data, test_data])\n",
    "X_train = train_data[TEXT_COL]\n",
    "X_test = test_data[TEXT_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique labels\n",
    "labels = all_data[LABEL_COL].unique()\n",
    "args.labels = np.array(sorted(labels))\n",
    "args.num_labels = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and embedding\n",
    "The data is then tokenized and embedded using glove embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = GlovePreprocessor(all_data[TEXT_COL], token_count_thresh, max_sentence_token_count)\n",
    "\n",
    "# append labels to tokenizer output\n",
    "df_train = pd.concat([train_data[LABEL_COL], preprocessor.preprocess(X_train)], axis=1)\n",
    "df_test = pd.concat([test_data[LABEL_COL], preprocessor.preprocess(X_test)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainer\n",
    "Then, we create and train the explainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding is initialized fully randomly.\n",
      "embedding is initialized fully randomly.\n",
      "embedding is initialized fully randomly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:10<00:00, 10.58s/it]\n"
     ]
    }
   ],
   "source": [
    "explainer = ThreePlayerIntrospectiveExplainer(args, preprocessor, classifier_type=\"RNN\")\n",
    "if not QUICK_RUN:\n",
    "    classifier = explainer.fit(df_train, df_test) # TODO: add back pretraining classifier\n",
    "else:\n",
    "    classifier = explainer.fit(df_train, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the explainer and measure its performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not QUICK_RUN:\n",
    "    explainer.score(df_test, n_examples_displayed=0)\n",
    "    print(\"Test sparsity: \", explainer.model.avg_sparsity)\n",
    "    print(\"Test accuracy: \", explainer.model.avg_accuracy, \"% Anti-accuracy: \", explainer.model.avg_anti_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local importances\n",
    "We can display the found local importances (the most and least important words for a given sentence):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v-yohwa\\AppData\\Local\\Continuum\\anaconda3\\envs\\interpret_cpu\\lib\\site-packages\\numpy\\core\\fromnumeric.py:61: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Enter a sentence that needs to be interpreted\n",
    "sentence = \"This great movie was really good\"\n",
    "label = 1\n",
    "\n",
    "local_explanation = explainer.explain_local(sentence, label, preprocessor, hard_importances=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize explanations\n",
    "We can visualize local feature importances as a heatmap over words in the document and view importance values of individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:rgba(135,206,250,0.911749005317688);\">this</span> <span style=\"background-color:rgba(135,206,250,0.8880453109741211);\">great</span> <span style=\"background-color:rgba(135,206,250,0.8948152661323547);\">movie</span> <span style=\"background-color:rgba(135,206,250,0.8724318742752075);\">was</span> <span style=\"background-color:rgba(135,206,250,0.8809492588043213);\">really</span> <span style=\"background-color:rgba(135,206,250,0.8774576187133789);\">good</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explainer.visualize(local_explanation._local_importance_values, local_explanation._features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e353a871cb80490b824d9a182e1dddbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExplanationWidget(value={'text': ['this', 'great', 'movie', 'was', 'really', 'good'], 'prediction': [0, 1], 'c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<interpret_text.widget.ExplanationDashboard.ExplanationDashboard at 0x275b0010e80>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExplanationDashboard(local_explanation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (interpret_cpu)",
   "language": "python",
   "name": "interpret_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
