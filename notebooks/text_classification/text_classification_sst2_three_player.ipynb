{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright (c) Microsoft Corporation. All rights reserved.*\n",
    "\n",
    "*Licensed under the MIT License.*\n",
    "\n",
    "# Text Classification of SST-2 Sentences using a 3-Player Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from interpret_text.three_player_introspective.three_player_introspective_explainer import ThreePlayerIntrospectiveExplainer\n",
    "from interpret_text.common.utils_three_player import load_pandas_df, GloveTokenizer\n",
    "from interpret_text.widget import ExplanationDashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook, we train and evaluate a  [three-player explainer](http://people.csail.mit.edu/tommi/papers/YCZJ_EMNLP2019.pdf) model on a subset of the [SST-2](https://nlp.stanford.edu/sentiment/index.html/) dataset. To run this notebook, we used the SST-2 data files provided [here](https://github.com/AcademiaSinicaNLPLab/sentiment_dataset). You should download files matching data/sst2.binary.* into a folder and point DATA_FOLDER (below) to that folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters\n",
    "Here we set some parameters that we use for our modeling task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing parameters\n",
    "DATA_FOLDER = \"../../../data/sst2\"\n",
    "LABEL_COL = \"labels\" \n",
    "TEXT_COL = \"sentences\"\n",
    "token_count_thresh = 1\n",
    "max_sentence_token_count = 70\n",
    "\n",
    "# training procedure params\n",
    "pre_trained_model_prefix = 'pre_trained_cls.model'\n",
    "save_path = os.path.join(\"..\", \"models\")\n",
    "model_prefix = \"sst2rnpmodel\"\n",
    "save_best_model = True\n",
    "pre_train_cls = True\n",
    "\n",
    "# arguments for the model\n",
    "class Argument():\n",
    "    def __init__(self):\n",
    "        # to initialize classifierModule and introspectionGeneratorModule\n",
    "        self.embedding_dim = 100\n",
    "        self.hidden_dim = 200\n",
    "        self.layer_num = 1\n",
    "        self.z_dim = 2\n",
    "        self.dropout_rate = 0.5\n",
    "\n",
    "        # to init only introspectionGeneratorModule\n",
    "        self.num_labels = 2\n",
    "        self.label_embedding_dim = 400\n",
    "        self.fixed_classifier = True\n",
    "\n",
    "        # to init model\n",
    "        self.fine_tuning = False\n",
    "        self.cuda = True\n",
    "        self.batch_size = 40\n",
    "        self.lambda_sparsity = 1.0\n",
    "        self.lambda_continuity = 1.0\n",
    "        self.lambda_anti = 1.0\n",
    "        self.exploration_rate = 0.05\n",
    "        self.count_tokens = 8\n",
    "        self.count_pieces = 4\n",
    "        self.lambda_acc_gap = 1.2\n",
    "        self.lr=0.001\n",
    "        self.embedding_path = os.path.join(DATA_FOLDER, \"hglove.6B.100d.txt\")\n",
    "args = Argument()\n",
    "args_dict = vars(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset\n",
    "We start by loading a subset of the data for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: load dataset to blob storage\n",
    "df_train = load_pandas_df('train', LABEL_COL, TEXT_COL)\n",
    "df_test = load_pandas_df('test', LABEL_COL, TEXT_COL)\n",
    "df_all = pd.concat([df_train, df_test])\n",
    "x_train = df_train[TEXT_COL]\n",
    "x_test = df_test[TEXT_COL]\n",
    "y_train = df_train[LABEL_COL]\n",
    "y_test = df_train[LABEL_COL]\n",
    "labels = df_all[LABEL_COL].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and embedding\n",
    "The data is then tokenized and embedded using glove embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      labels                                          sentences  \\\n",
      "0          1  a stirring , funny and finally transporting re...   \n",
      "1          0  apparently reassembled from the cutting-room f...   \n",
      "2          0  they presume their audience wo n't sit still f...   \n",
      "3          1  this is a visually stunning rumination on love...   \n",
      "4          1  jonathan parker 's bartleby should have been t...   \n",
      "...      ...                                                ...   \n",
      "1816       0  an often-deadly boring , strange reading of a ...   \n",
      "1817       0  the problem with concept films is that if the ...   \n",
      "1818       0  safe conduct , however ambitious and well-inte...   \n",
      "1819       0  a film made with as little wit , interest , an...   \n",
      "1820       0  but here 's the real damn : it is n't funny , ...   \n",
      "\n",
      "                                                 tokens  \\\n",
      "0     [2, 3, 4, 5, 6, 7, 8, 1, 10, 11, 6, 12, 13, 6,...   \n",
      "1     [17, 1, 19, 12, 1, 21, 10, 22, 23, 24, 25, 26,...   \n",
      "2     [27, 1, 29, 30, 31, 32, 33, 34, 35, 2, 36, 37,...   \n",
      "3     [54, 55, 2, 56, 57, 58, 59, 60, 4, 61, 4, 62, ...   \n",
      "4     [67, 68, 69, 70, 71, 72, 73, 12, 1, 10, 12, 1,...   \n",
      "...                                                 ...   \n",
      "1816  [241, 1, 4114, 4, 2876, 4364, 10, 2, 134, 3279...   \n",
      "1817  [12, 2231, 93, 1949, 16, 55, 88, 175, 12, 1949...   \n",
      "1818  [1139, 1140, 4, 38, 613, 6, 317, 4, 2293, 117,...   \n",
      "1819  [2, 87, 812, 93, 144, 106, 1359, 4, 277, 4, 6,...   \n",
      "1820  [150, 1876, 69, 12, 343, 1519, 204, 165, 55, 3...   \n",
      "\n",
      "                                                   mask  counts  \n",
      "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      17  \n",
      "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...      12  \n",
      "2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      35  \n",
      "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      20  \n",
      "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      15  \n",
      "...                                                 ...     ...  \n",
      "1816  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      19  \n",
      "1817  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      22  \n",
      "1818  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      18  \n",
      "1819  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      22  \n",
      "1820  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...      14  \n",
      "\n",
      "[8741 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GloveTokenizer(df_all[TEXT_COL], token_count_thresh, max_sentence_token_count)\n",
    "word_vocab = tokenizer.word_vocab\n",
    "\n",
    "# append tokenizations to data\n",
    "df_train = pd.concat([df_train, tokenizer.tokenize(x_train)], axis=1)\n",
    "df_test = pd.concat([df_test, tokenizer.tokenize(x_test)], axis=1)\n",
    "df_all = pd.concat([df_train, df_test])\n",
    "x_train = df_train[TEXT_COL]\n",
    "x_test = df_test[TEXT_COL]\n",
    "y_train = df_train[LABEL_COL]\n",
    "y_test = df_train[LABEL_COL]\n",
    "labels = df_all[LABEL_COL].unique()\n",
    "print(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainer\n",
    "Then, we create and train the explainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v-yohwa\\AppData\\Local\\Continuum\\anaconda3\\envs\\interpret_cpu\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding is initialized fully randomly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v-yohwa\\AppData\\Local\\Continuum\\anaconda3\\envs\\interpret_cpu\\lib\\site-packages\\torch\\nn\\_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-training the classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c16653e8b38e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mThreePlayerIntrospectiveExplainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_vocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpretrain_cls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\v-yohwa\\interpret-community-text\\python\\interpret_text\\three_player_introspective\\three_player_introspective_explainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, df_train, df_test, batch_size, num_iteration, pretrain_cls)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpretrain_cls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pre-training the classifier'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpretrain_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[1;31m# encode the list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\v-yohwa\\interpret-community-text\\python\\interpret_text\\three_player_introspective\\three_player_introspective_model.py\u001b[0m in \u001b[0;36mpretrain_classifier\u001b[1;34m(self, df_train, df_test, batch_size, num_iteration, test_iteration)\u001b[0m\n\u001b[0;32m    664\u001b[0m             \u001b[1;31m# sample a batch of data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 666\u001b[1;33m             \u001b[0mbatch_x_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_cls_one_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_x_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_m_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\v-yohwa\\interpret-community-text\\python\\interpret_text\\three_player_introspective\\three_player_introspective_model.py\u001b[0m in \u001b[0;36mgenerate_data\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m             \u001b[0mbatch_x_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_x_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    583\u001b[0m             \u001b[0mbatch_m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_m_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m             \u001b[0mbatch_y_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_y_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\interpret_cpu\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    160\u001b[0m         raise RuntimeError(\n\u001b[0;32m    161\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m--> 162\u001b[1;33m     \u001b[0m_check_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[0m_cudart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\interpret_cpu\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "explainer = ThreePlayerIntrospectiveExplainer(args, word_vocab)\n",
    "classifier = explainer.fit(df_train, df_test, args.batch_size, num_iteration=1000, pretrain_cls=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the explainer and measure its performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, anti_accuracy, sparsity = explainer.score(df_test)\n",
    "print(\"Test sparsity: \", sparsity)\n",
    "print(\"Test accuracy: \", accuracy, \"% Anti-accuracy: \", anti_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local importances\n",
    "We can display the found local importances (the most and least important words for a given sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Enter a sentence that needs to be interpreted\n",
    "sentence = \"This great movie was really good\"\n",
    "label = 0\n",
    "\n",
    "# Tokenize the sentence\n",
    "df_sentence = pd.DataFrame.from_dict({TEXT_COL: [sentence], LABEL_COL: [label]})\n",
    "tokenizer = GloveTokenizer(df_sentence[TEXT_COL], token_count_thresh, max_sentence_token_count)\n",
    "df_sentence = pd.concat([df_sentence, tokenizer.tokenize(df_sentence[TEXT_COL])], axis=1)\n",
    "local_explanantion = explainer.explain_local(sentence, df_sentence, np.array([0, 1]), hard_importances=False)\n",
    "\n",
    "# Visualize local feature importances as a heatmap over words in the document\n",
    "# TODO: a less hacky way of getting words\n",
    "explainer.visualize(local_explanantion._local_importance_values, local_explanantion._features)\n",
    "\n",
    "ExplanationDashboard(local_explanantion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(local_explanantion._local_importance_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
